{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2646c0e-8d89-4638-8e69-2160276d635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from functools import partial\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f2e13b-7017-4fdf-9b5a-801816c921e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom modules\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.models.maet_model import MAET\n",
    "from src.data.seedvii_dataset import SEEDVII_Dataset\n",
    "from src.training.train_multimodal import MultimodalTrainer, train_subject_dependent, train_cross_subject\n",
    "from src.utils.safe_forward import safe_model_forward\n",
    "from src.training.evaluation_utils import compute_metrics, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0552586c-e7e5-4391-a2e7-f0311ae96795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration and Setup\n",
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'seed': 42,\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 1e-3,\n",
    "    'weight_decay': 1e-4,\n",
    "    'val_split': 0.2,\n",
    "    'num_workers': 4,\n",
    "    'gradient_reversal_alpha': 0.5,\n",
    "    'domain_loss_weight': 0.1,\n",
    "    'early_stopping': 10,\n",
    "    'save_model': True,\n",
    "    'model': {\n",
    "        'embed_dim': 32,\n",
    "        'depth': 3,\n",
    "        'num_heads': 4,\n",
    "        'domain_generalization': True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dataset configuration\n",
    "DATA_DIR = \"../data/SEED-VII\"\n",
    "SUBSET_RATIO = 0.5  # Use 50% of data for quick experiments\n",
    "\n",
    "print(f\"Configuration loaded\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa95ee3-8acc-458b-a667-a599b427d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Dataset Loading and Exploration\n",
    "print(\"=== DATASET EXPLORATION ===\")\n",
    "\n",
    "# Load dataset for exploration\n",
    "dataset = SEEDVII_Dataset(DATA_DIR, 'multimodal', SUBSET_RATIO)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} samples\")\n",
    "print(f\"EEG features shape: {dataset.eeg_features.shape}\")\n",
    "print(f\"Eye features shape: {dataset.eye_features.shape}\")\n",
    "print(f\"Number of classes: {dataset.num_classes}\")\n",
    "print(f\"Number of subjects: {len(np.unique(dataset.subject_labels))}\")\n",
    "\n",
    "# Analyze class distribution\n",
    "emotion_counts = pd.Series(dataset.emotion_labels).value_counts().sort_index()\n",
    "print(\"\\\\nEmotion class distribution:\")\n",
    "for i, count in emotion_counts.items():\n",
    "    emotion_name = dataset.emotion_labels.get(i, f\"Class_{i}\")\n",
    "    print(f\"  {i}: {emotion_name} - {count} samples\")\n",
    "\n",
    "# Analyze subject distribution  \n",
    "subject_counts = pd.Series(dataset.subject_labels).value_counts().sort_index()\n",
    "print(f\"\\\\nSubject distribution:\")\n",
    "print(f\"  Subjects: {subject_counts.index.tolist()}\")\n",
    "print(f\"  Samples per subject: {subject_counts.values.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3710f337-ca56-4d2d-81ae-a7f2a58fdaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture Exploration\n",
    "print(\"=== MODEL ARCHITECTURE ===\")\n",
    "\n",
    "# Create sample model\n",
    "sample_model = MAET(\n",
    "    eeg_dim=310,\n",
    "    eye_dim=33, \n",
    "    num_classes=7,\n",
    "    embed_dim=32,\n",
    "    depth=3,\n",
    "    num_heads=4,\n",
    "    domain_generalization=True,\n",
    "    num_domains=20\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in sample_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in sample_model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Test forward pass with sample data\n",
    "sample_batch = dataset\n",
    "eeg_sample = sample_batch['eeg'].unsqueeze(0)\n",
    "eye_sample = sample_batch['eye'].unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Test different modality combinations\n",
    "    print(\"\\\\nTesting forward passes:\")\n",
    "    \n",
    "    # Multimodal\n",
    "    pred_multi, additional = safe_model_forward(sample_model, eeg=eeg_sample, eye=eye_sample)\n",
    "    print(f\"  Multimodal: {pred_multi.shape}\")\n",
    "    if additional:\n",
    "        print(f\"    Domain output: {additional.shape}\")\n",
    "    \n",
    "    # EEG only\n",
    "    pred_eeg, _ = safe_model_forward(sample_model, eeg=eeg_sample, eye=None)\n",
    "    print(f\"  EEG only: {pred_eeg.shape}\")\n",
    "    \n",
    "    # Eye only  \n",
    "    pred_eye, _ = safe_model_forward(sample_model, eeg=None, eye=eye_sample)\n",
    "    print(f\"  Eye only: {pred_eye.shape}\")\n",
    "\n",
    "del sample_model  # Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaf3cbb-a76f-46d9-8d17-4dc594b92d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Subject Experiment (Quick Test)\n",
    "print(\"=== SINGLE SUBJECT EXPERIMENT ===\")\n",
    "\n",
    "# Select one subject for detailed analysis\n",
    "target_subject = 0\n",
    "subject_mask = dataset.subject_labels == target_subject\n",
    "subject_indices = np.where(subject_mask)\n",
    "\n",
    "print(f\"Subject {target_subject}: {len(subject_indices)} samples\")\n",
    "\n",
    "if len(subject_indices) >= 20:  # Ensure sufficient samples\n",
    "    # Create subject-specific dataset\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        subject_indices, test_size=0.3, random_state=42,\n",
    "        stratify=dataset.emotion_labels[subject_indices]\n",
    "    )\n",
    "    \n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    val_dataset = Subset(dataset, val_indices)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Quick training\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = MAET(eeg_dim=310, eye_dim=33, num_classes=7, embed_dim=32).to(device)\n",
    "    \n",
    "    trainer = MultimodalTrainer(CONFIG)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    print(\"\\\\nQuick training (10 epochs):\")\n",
    "    train_history = []\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        # Train\n",
    "        train_loss, train_acc = trainer.train_epoch(model, train_loader, optimizer, criterion)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc, val_f1, val_preds, val_labels = trainer.validate(\n",
    "            model, val_loader, criterion\n",
    "        )\n",
    "        \n",
    "        train_history.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'train_acc': train_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'val_f1': val_f1\n",
    "        })\n",
    "        \n",
    "        if epoch % 2 == 0:\n",
    "            print(f\"  Epoch {epoch+1}: Train {train_acc:.1f}%, Val {val_acc:.1f}%\")\n",
    "    \n",
    "    # Plot training history\n",
    "    epochs = [h['epoch'] for h in train_history]\n",
    "    train_accs = [h['train_acc'] for h in train_history]\n",
    "    val_accs = [h['val_acc'] for h in train_history]\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(epochs, train_accs, 'b-', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_accs, 'r-', label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title(f'Subject {target_subject} Training Progress')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\\\nBest validation accuracy: {max(val_accs):.2f}%\")\n",
    "    \n",
    "    del model, trainer  # Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73e8c31-3d9e-4744-b7f0-8a628234b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multimodal vs Unimodal Comparison\n",
    "print(\"=== MODALITY COMPARISON ===\")\n",
    "\n",
    "modalities = ['multimodal', 'eeg', 'eye']\n",
    "results_comparison = {}\n",
    "\n",
    "for modality in modalities:\n",
    "    print(f\"\\\\nTesting {modality} modality...\")\n",
    "    \n",
    "    # Load modality-specific dataset\n",
    "    mod_dataset = SEEDVII_Dataset(DATA_DIR, modality, SUBSET_RATIO)\n",
    "    \n",
    "    # Use first subject for quick test\n",
    "    subject_mask = mod_dataset.subject_labels == 0\n",
    "    subject_indices = np.where(subject_mask)\n",
    "    \n",
    "    if len(subject_indices) >= 20:\n",
    "        train_indices, val_indices = train_test_split(\n",
    "            subject_indices, test_size=0.3, random_state=42,\n",
    "            stratify=mod_dataset.emotion_labels[subject_indices]\n",
    "        )\n",
    "        \n",
    "        train_dataset = Subset(mod_dataset, train_indices)\n",
    "        val_dataset = Subset(mod_dataset, val_indices)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "        \n",
    "        # Create modality-specific model\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = MAET(\n",
    "            eeg_dim=310 if modality in ['eeg', 'multimodal'] else 0,\n",
    "            eye_dim=33 if modality in ['eye', 'multimodal'] else 0,\n",
    "            num_classes=7,\n",
    "            embed_dim=32\n",
    "        ).to(device)\n",
    "        \n",
    "        trainer = MultimodalTrainer(CONFIG)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Quick training\n",
    "        best_val_acc = 0.0\n",
    "        for epoch in range(15):\n",
    "            train_loss, train_acc = trainer.train_epoch(model, train_loader, optimizer, criterion)\n",
    "            val_loss, val_acc, val_f1, _, _ = trainer.validate(model, val_loader, criterion)\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "        \n",
    "        results_comparison[modality] = best_val_acc\n",
    "        print(f\"  {modality}: {best_val_acc:.2f}%\")\n",
    "        \n",
    "        del model, trainer\n",
    "\n",
    "# Comparison visualization\n",
    "if results_comparison:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    modalities = list(results_comparison.keys())\n",
    "    accuracies = list(results_comparison.values())\n",
    "    \n",
    "    bars = plt.bar(modalities, accuracies, color=['skyblue', 'lightgreen', 'salmon'])\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.ylabel('Best Validation Accuracy (%)')\n",
    "    plt.title('Modality Comparison (Subject 0)')\n",
    "    plt.ylim(0, max(accuracies) * 1.2)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\\\nModality Ranking:\")\n",
    "    sorted_results = sorted(results_comparison.items(), key=lambda x: x, reverse=True)\n",
    "    for rank, (modality, accuracy) in enumerate(sorted_results, 1):\n",
    "        print(f\"  {rank}. {modality}: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb88fc3-37a3-4396-9d41-5df220e204fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Subject Analysis Preview\n",
    "print(\"=== CROSS-SUBJECT ANALYSIS PREVIEW ===\")\n",
    "\n",
    "# Analyze subject variability\n",
    "subjects_to_analyze = np.unique(dataset.subject_labels)[:5]  # First 5 subjects\n",
    "subject_performance = {}\n",
    "\n",
    "print(\"Quick cross-subject generalization test...\")\n",
    "print(\"Training on subjects [0, 1, 2], testing on subject 3\")\n",
    "\n",
    "# Prepare cross-subject data\n",
    "train_subjects = [0, 1, 2]\n",
    "test_subject = 3\n",
    "\n",
    "train_mask = np.isin(dataset.subject_labels, train_subjects)\n",
    "test_mask = dataset.subject_labels == test_subject\n",
    "\n",
    "train_indices = np.where(train_mask)\n",
    "test_indices = np.where(test_mask)\n",
    "\n",
    "if len(test_indices) >= 10:\n",
    "    print(f\"Train samples: {len(train_indices)}\")\n",
    "    print(f\"Test samples: {len(test_indices)}\")\n",
    "    \n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    test_dataset = Subset(dataset, test_indices)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    # Train model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = MAET(\n",
    "        eeg_dim=310, eye_dim=33, num_classes=7, embed_dim=32,\n",
    "        domain_generalization=True, num_domains=len(train_subjects)\n",
    "    ).to(device)\n",
    "    \n",
    "    trainer = MultimodalTrainer(CONFIG)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    print(\"\\\\nTraining progress:\")\n",
    "    for epoch in range(20):\n",
    "        train_loss, train_acc = trainer.train_epoch(model, train_loader, optimizer, criterion)\n",
    "        if epoch % 5 == 0:\n",
    "            print(f\"  Epoch {epoch}: Train {train_acc:.1f}%\")\n",
    "    \n",
    "    # Test\n",
    "    test_loss, test_acc, test_f1, test_preds, test_labels = trainer.validate(\n",
    "        model, test_loader, criterion\n",
    "    )\n",
    "    \n",
    "    print(f\"\\\\nCross-subject test results:\")\n",
    "    print(f\"  Test accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"  Test F1-score: {test_f1:.2f}%\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(test_labels, test_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=dataset.emotion_labels.values(),\n",
    "                yticklabels=dataset.emotion_labels.values())\n",
    "    plt.title(f'Cross-Subject Confusion Matrix (Test Subject {test_subject})')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    del model, trainer\n",
    "\n",
    "# %%\n",
    "# Cell 8: Attention Visualization (if applicable)\n",
    "print(\"=== ATTENTION ANALYSIS ===\")\n",
    "\n",
    "# This cell would contain attention weight visualization code\n",
    "# For now, we'll create a placeholder for future implementation\n",
    "\n",
    "print(\"Attention visualization functionality to be implemented...\")\n",
    "print(\"This would include:\")\n",
    "print(\"- Visualization of multi-head attention weights\")\n",
    "print(\"- Analysis of which EEG/eye features are most important\")\n",
    "print(\"- Temporal attention patterns\")\n",
    "print(\"- Cross-modal attention interactions\")\n",
    "\n",
    "# Placeholder for attention extraction\n",
    "def extract_attention_weights(model, dataloader, num_samples=5):\n",
    "    \"\"\"Extract attention weights from transformer blocks\"\"\"\n",
    "    # This would extract attention weights during forward pass\n",
    "    # for visualization and analysis\n",
    "    pass\n",
    "\n",
    "# %%\n",
    "# Cell 9: Hyperparameter Analysis\n",
    "print(\"=== HYPERPARAMETER SENSITIVITY ===\")\n",
    "\n",
    "# Test different embedding dimensions\n",
    "embed_dims = [16, 32, 64]\n",
    "embed_results = {}\n",
    "\n",
    "print(\"Testing different embedding dimensions...\")\n",
    "\n",
    "for embed_dim in embed_dims:\n",
    "    print(f\"\\\\nTesting embed_dim={embed_dim}...\")\n",
    "    \n",
    "    # Use small dataset for quick test\n",
    "    quick_indices = np.random.choice(len(dataset), 1000, replace=False)\n",
    "    quick_dataset = Subset(dataset, quick_indices)\n",
    "    \n",
    "    train_indices, val_indices = train_test_split(\n",
    "        range(len(quick_dataset)), test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    train_subset = Subset(quick_dataset, train_indices)\n",
    "    val_subset = Subset(quick_dataset, val_indices)\n",
    "    \n",
    "    train_loader = DataLoader(train_subset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    # Create model with specific embed_dim\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = MAET(\n",
    "        eeg_dim=310, eye_dim=33, num_classes=7,\n",
    "        embed_dim=embed_dim, depth=2, num_heads=2\n",
    "    ).to(device)\n",
    "    \n",
    "    trainer = MultimodalTrainer(CONFIG)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Quick training\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(10):\n",
    "        train_loss, train_acc = trainer.train_epoch(model, train_loader, optimizer, criterion)\n",
    "        val_loss, val_acc, val_f1, _, _ = trainer.validate(model, val_loader, criterion)\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "    \n",
    "    embed_results[embed_dim] = best_val_acc\n",
    "    print(f\"  Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    del model, trainer\n",
    "\n",
    "# Visualize hyperparameter results\n",
    "if embed_results:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    dims = list(embed_results.keys())\n",
    "    accs = list(embed_results.values())\n",
    "    \n",
    "    plt.plot(dims, accs, 'bo-', linewidth=2, markersize=8)\n",
    "    plt.xlabel('Embedding Dimension')\n",
    "    plt.ylabel('Best Validation Accuracy (%)')\n",
    "    plt.title('Embedding Dimension vs Performance')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xticks(dims)\n",
    "    \n",
    "    # Annotate points\n",
    "    for dim, acc in zip(dims, accs):\n",
    "        plt.annotate(f'{acc:.1f}%', (dim, acc), textcoords=\"offset points\",\n",
    "                    xytext=(0,10), ha='center')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# %%\n",
    "# Cell 10: Summary and Next Steps\n",
    "print(\"=== EXPERIMENT SUMMARY ===\")\n",
    "\n",
    "print(\"\\\\nCompleted experiments:\")\n",
    "print(\"✓ Dataset exploration and analysis\")\n",
    "print(\"✓ Model architecture testing\")\n",
    "print(\"✓ Single subject training validation\")\n",
    "print(\"✓ Multimodal vs unimodal comparison\")\n",
    "print(\"✓ Cross-subject generalization preview\")\n",
    "print(\"✓ Hyperparameter sensitivity analysis\")\n",
    "\n",
    "print(\"\\\\nKey findings:\")\n",
    "if 'results_comparison' in locals():\n",
    "    best_modality = max(results_comparison, key=results_comparison.get)\n",
    "    print(f\"- Best performing modality: {best_modality} ({results_comparison[best_modality]:.1f}%)\")\n",
    "\n",
    "if 'embed_results' in locals():\n",
    "    best_embed = max(embed_results, key=embed_results.get)\n",
    "    print(f\"- Optimal embedding dimension: {best_embed} ({embed_results[best_embed]:.1f}%)\")\n",
    "\n",
    "print(\"\\\\nNext steps for full experiments:\")\n",
    "print(\"- Run complete subject-dependent validation\")\n",
    "print(\"- Perform full cross-subject (LOSO) evaluation\")\n",
    "print(\"- Implement attention visualization\")\n",
    "print(\"- Conduct comprehensive ablation studies\")\n",
    "print(\"- Optimize hyperparameters with proper grid search\")\n",
    "print(\"- Add statistical significance testing\")\n",
    "\n",
    "print(\"\\\\nTo run full experiments:\")\n",
    "print(\"1. Increase SUBSET_RATIO to 1.0 for full dataset\")\n",
    "print(\"2. Run train_subject_dependent() and train_cross_subject()\")\n",
    "print(\"3. Use proper cross-validation with multiple random seeds\")\n",
    "print(\"4. Implement early stopping and model checkpointing\")\n",
    "\n",
    "# %%\n",
    "# Cell 11: Cleanup\n",
    "print(\"=== CLEANUP ===\")\n",
    "\n",
    "# Clear variables and free memory\n",
    "if 'dataset' in locals():\n",
    "    del dataset\n",
    "if 'quick_dataset' in locals():\n",
    "    del quick_dataset\n",
    "\n",
    "# Clear GPU memory if using CUDA\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "print(\"Memory cleanup completed\")\n",
    "print(\"Notebook execution finished successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17954eb5-098f-4364-975b-911e07dd2da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
