

# Experiment Information
experiment:
  name: "MAET_MultimodalEmotion"
  description: "Multimodal attention-enhanced transformer for EEG-eye emotion recognition"
  version: "1.0.0"
  tags: ["multimodal", "emotion", "attention", "transformer"]

# Dataset Configuration
data:
  data_dir: "./data/SEED-VII"
  modality: "multimodal"  # Options: "eeg", "eye", "multimodal"
  subset_ratio: 1.0       # Fraction of dataset to use (1.0 = full dataset)
  num_classes: 7
  class_names: ["Neutral", "Sad", "Fear", "Happy", "Disgust", "Surprise", "Angry"]
  
  # Data loading
  batch_size: 32
  num_workers: 4
  pin_memory: true
  
  # Data splits
  val_split: 0.2          # Validation split ratio
  test_split: 0.1         # Test split ratio (if using hold-out test set)
  
  # Preprocessing
  preprocessing:
    normalize_eeg: true
    normalize_eye: true
    augmentation:
      enabled: false
      noise_level: 0.01
      dropout_ratio: 0.1

# Model Configuration  
model:
  # Architecture
  embed_dim: 32           # Embedding dimension for multimodal features
  depth: 3                # Number of transformer blocks
  num_heads: 4            # Number of attention heads
  
  # Modality-specific settings
  eeg_dim: 310           # EEG feature dimension
  eye_dim: 33            # Eye tracking feature dimension
  num_views: 5           # Number of views in multi-view embedding
  
  # Domain adaptation
  domain_generalization: true
  num_domains: 20         # Number of subjects/domains
  
  # Regularization
  dropout: 0.1
  attention_dropout: 0.1

# Training Configuration
training:
  # Optimization
  optimizer: "adamw"
  learning_rate: 1e-3
  weight_decay: 1e-4
  momentum: 0.9           # For SGD optimizer
  
  # Learning rate scheduling
  scheduler: "cosine"     # Options: "cosine", "step", "exponential", "plateau"
  min_lr: 1e-6
  warmup_epochs: 5
  
  # Training parameters
  num_epochs: 100
  gradient_clipping: 1.0
  
  # Loss configuration
  loss_function: "cross_entropy"
  label_smoothing: 0.1
  
  # Domain adaptation loss
  domain_loss_weight: 0.1
  gradient_reversal_alpha: 1.0
  gradient_reversal_schedule: "linear"  # Options: "linear", "exponential", "constant"
  
  # Regularization
  early_stopping: 10      # Patience for early stopping (0 to disable)
  
  # Checkpointing
  save_model: true
  save_every_n_epochs: 10
  save_best_only: true

# Evaluation Configuration
evaluation:
  # Metrics to compute
  metrics: ["accuracy", "f1_macro", "f1_weighted", "precision", "recall"]
  
  # Evaluation modes
  subject_dependent: true
  cross_subject: true     # Leave-one-subject-out validation
  
  # Analysis
  confusion_matrix: true
  per_class_analysis: true
  per_subject_analysis: true
  
  # Robustness testing
  noise_robustness: true
  noise_levels: [0.0, 0.1, 0.2, 0.3]

# Experiment Modes
experiments:
  # Subject-dependent experiments
  subject_dependent:
    enabled: true
    subjects_to_test: 5    # Number of subjects to test (for quick experiments)
    train_ratio: 0.7
    
  # Cross-subject experiments  
  cross_subject:
    enabled: true
    test_subjects: 3       # Number of subjects to use as test (for quick experiments)
    domain_adaptation: true
    
  # Ablation studies
  ablation:
    enabled: false
    studies:
      - "no_attention"
      - "single_modality_eeg"
      - "single_modality_eye"
      - "no_domain_adaptation"

# Hardware Configuration
hardware:
  device: "auto"          # Options: "auto", "cpu", "cuda", "cuda:0", etc.
  mixed_precision: false  # Enable mixed precision training
  compile_model: false    # Use torch.compile for optimization

# Logging and Monitoring
logging:
  log_level: "INFO"
  log_interval: 100       # Log every N batches
  
  # Weights & Biases integration
  wandb:
    enabled: false
    project: "multimodal-emotion"
    entity: "your-username"
    
  # TensorBoard integration
  tensorboard:
    enabled: true
    log_dir: "./logs"

# Reproducibility
random_seed: 42
deterministic: true

# Output Configuration
output:
  results_dir: "./results"
  checkpoints_dir: "./checkpoints"
  figures_dir: "./figures"
  
  # File formats
  save_predictions: true
  save_features: false    # Save learned features for analysis
  export_onnx: false      # Export model to ONNX format
```
